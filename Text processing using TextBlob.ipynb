{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TextBlob : Simplified Text Processing\n",
    "    \n",
    "TextBlob is a python 2 and 3 library for processing textual data. it provides a simple API for diving into common natural lanugauge preprocessing (NLP) tasks such as part of speach tagging, Noun phrase extraction , sentiment analysis, classification , translation and more \n",
    "Textblob stands on the gaint shoulders of NLTK and pattern  and plays nicely with both\n",
    "\n",
    "\n",
    " -Features\n",
    "    Noun phrase extraction \n",
    "    part of speach tagging\n",
    "    sentiment analysis\n",
    "    classification(naive bays Descison tree)\n",
    "    language translation and detection powered  by google translate\n",
    "    Tokenization (splitting text into words and sentences)\n",
    "    word and phrase frequencies\n",
    "    phrase\n",
    "    n-grams\n",
    "    word inflection(pluralzation and singularization) and lemmatization \n",
    "    spelling correction\n",
    "    add new models or languages through extensions\n",
    "    wordnet integration\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\adarsh_huggi\\appdata\\roaming\\python\\python37\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adarsh_huggi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.31.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\adarsh_huggi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\adarsh_huggi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\adarsh_huggi\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "#installation\n",
    "!pip install textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki =TextBlob(\"i Love Natural launguage Processing , not you\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part of speach(pos) tagging \n",
    "part of speach tags can be accessed though tags property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NN'),\n",
       " ('Love', 'NNP'),\n",
       " ('Natural', 'NNP'),\n",
       " ('launguage', 'NN'),\n",
       " ('Processing', 'NNP'),\n",
       " ('not', 'RB'),\n",
       " ('you', 'PRP')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun phrase extraction\n",
    "Similarly , Noun phrases are accessed through the noun phrase property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Adarsh_huggi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['love', 'natural launguage', 'processing'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "The sentiment property  returns a named tuple of the form sentiment (polarity , subjectivity), the polarity score is a float within the range [-1.0,1.0], the subjectivity is float within the range[0,0,1,0] whrere 0.0 is very objective and 1.0 is very subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial =TextBlob(\"Textblob is amazingly simple to use , what great fun!\")\n",
    "testimonial.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4357142857142857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testimonial.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Data', 'is', 'a', 'new', 'fuel.Explicit', 'is', 'better', 'than', 'implicitSimple', 'is', 'better', 'than', 'complex'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen =TextBlob(\"Data is a new fuel.\"\n",
    "             \"Explicit is better than implicit\"\n",
    "             \"Simple is better than complex.\")\n",
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Data is a new fuel.Explicit is better than implicitSimple is better than complex.\")]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is a new fuel.Explicit is better than implicitSimple is better than complex.\n"
     ]
    }
   ],
   "source": [
    "for sentence in zen.sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'in', 'python', '3.6'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence =TextBlob(\"Use 4 spaces per indentation in python 3.6\")\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uses'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[0].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lion'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "q= Word('lions')\n",
    "q.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q =Word(\"went\")\n",
    "q.lemmatize(\"v\") #pass the wordnet part of speach(verb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet Integration\n",
    "\n",
    "you can access the synets for a Word via the synsets property or the get synsets method optionally passing in a parts of speech\n",
    "\n",
    "WordNet\n",
    "WordNet is lexical database that is dictionaly for the english launguage , it is specically for the nutral language processing \n",
    "\n",
    "#### synet\n",
    "it is a special kind of a simple interface that is presents in the NLTK for look up words in wordnet . synset instances are grouping synonymous that express the same type of concepts.\n",
    "some words have only one synset and some have several\n",
    "\n",
    "you can access the defination for each synset via the defination property or define method which can also take an optional part of speach(pos) argument "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the linear extent in space from one end to the other; the longest dimension of something that is fixed in place',\n",
       " 'continuance in time',\n",
       " 'the property of being the extent of something from beginning to end',\n",
       " 'size of the gap between two places',\n",
       " 'a section of something that is long and narrow']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"length\").definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also create synsets directly\n",
    "\n",
    "from textblob.wordnet import Synset\n",
    "octopus = Synset(\"octopus.n.02\")\n",
    "shrimp =Synset(\"shrimp.n.03\")\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordLists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Wordlist is just the python list with addition methods\n",
    "Wordlists will find it out the words which are in the sentence and ignore the spaces in between them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cow', 'sheep', 'octopus'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = TextBlob(\"cow sheep octopus\")\n",
    "animals.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['kine', 'sheep', 'octopodes'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.words.pluralize() #it ill pluralize the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Correction\n",
    "\n",
    "For correcting the words you can use correct() method to attemp spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you pronounce czechoslovakia?\n"
     ]
    }
   ],
   "source": [
    "g =TextBlob(\"can you pronounce czechuslovakia?\")\n",
    "print(g.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Word and Noun phrase Frequencies\n",
    "There are two ways to get the frequency of a word or noun phrases in the textblob\n",
    "the first one is though the word_counts dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent =TextBlob(\"She sales sea shells at the sea shore\")\n",
    "sent.word_counts['sea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you accesss the frequencies this way the search will not be case sensitive and words that are not found will have a frequency of 0\n",
    "the second way is to use the count() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.words.count('sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#you can specify whether or not the search should be case senesitve (defualt is False)\n",
    "\n",
    "sent.words.count(\"Sea\", case_sensitive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above example we have given \"Sea\" and ofcoouse sea is not avilable in the sentence , Sea is avialble in senetence but in lowsercase beacuse of that it given 0 as a result\n",
    "Each of these methods can also be used with noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.noun_phrases.count(\"sea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation and language detection\n",
    "TextBlobs can be translated between languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"कुछ तो बेहतर है तो कुछ नहीं\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob =TextBlob(u\"Something is better then nothing\")\n",
    "blob.translate(to='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Better than nothing\")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob =TextBlob(u\"总比没有好\")\n",
    "chinese_blob.translate(from_lang ='zh-CN', to ='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= TextBlob(u\" hi evey one \")\n",
    "d.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing \n",
    "use the parse() method used to parse the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP something/NN/B-NP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"And now for something completely different\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob are like Python strings\n",
    "you can use python substring syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Data is a new f\")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen [0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"DATA IS A NEW FUEL.EXPLICIT IS BETTER THAN IMPLICITSIMPLE IS BETTER THAN COMPLEX.\")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.find(\"than\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_blob =TextBlob(\"apple\")\n",
    "s_blob =TextBlob(\"samsung\")\n",
    "\n",
    "a_blob < s_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_blob = \"apple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"TextBlob\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-261e8556a797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma_blob\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' and '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms_blob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"TextBlob\") to str"
     ]
    }
   ],
   "source": [
    "a_blob + ' and ' + s_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple and samsung'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0} and {1}\".format(a_blob,s_blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "the textBlob.ngrams() method returns a list of tuples of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'then']),\n",
       " WordList(['better', 'then', 'never'])]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob =TextBlob(\"now is better then never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get start and End indices of sentences \n",
    "Use sentence start and sentence end to get the indeices where a sentence starts and ends with in a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is a new fuel.Explicit is better than implicitSimple is better than complex.\n",
      "--- start at index 0, Ends at index 81\n"
     ]
    }
   ],
   "source": [
    "for k in zen.sentences:\n",
    "    print(k)\n",
    "    print(\"--- start at index {}, Ends at index {}\".format(k.start, k.end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start bukding the text Classification system\n",
    "The textblob.classifiers module makes it simple to create sutome classifiers\n",
    "\n",
    "as an example ,lets create a custome sentiment analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Creating a Classifier\n",
    "first we'll create some training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =[\n",
    "    \n",
    "    ('I love this sandwith.','pos'),\n",
    "    ('this is amzing place!', 'pos'),\n",
    "    ('I feel very good about these beers', 'pos'),\n",
    "    ('this is my best work','pos'),\n",
    "    ('what an awsome view', 'pos'),\n",
    "    ('I do not like this resturant', 'neg'),\n",
    "    ('I am tired of this stuff', 'neg'),\n",
    "    (\"i can't deal with this\", \"neg\"),\n",
    "    (\"he is my sworn enemy!\", 'neg'),\n",
    "    (\"my boss is horrible\", \"neg\")\n",
    "    \n",
    "]\n",
    "\n",
    "test =[\n",
    "    (\"the beer was good\", 'pos'),\n",
    "    (\"i do not enjoy my job\",'neg'),\n",
    "    (\"i ain't feeling well dady today\", 'neg'),\n",
    "    (\"I feel amazing!\", 'pos'),\n",
    "    (\"Gary is a friend of mine\",'pos'),\n",
    "    (\"I can't belive i'am doing this\", 'neg')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl =NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loding Data from files\n",
    "\n",
    "you can also load from common files formates inclusing csv, json ,and tsv\n",
    " CSV files should be formated like this:\n",
    "        \n",
    "        I love this sandwich., pos\n",
    "        this is an amazing place!, pos\n",
    "        i do not like this resturant, neg\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying Text\n",
    "call the classify(text) method to use the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist =cl.prob_classify(\"I am suffering from cough and cold\")\n",
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob('neg'),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob('pos'),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying TextBlobs\n",
    "Another way to classify  text is to pass a classifier into the constructor of textblob and call its classify methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"Alcohol is good. But the hangover is horrible\", classifier =cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol is good.\n",
      "pos\n",
      "But the hangover is horrible\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "for b in blob.sentences:\n",
    "    print(b)\n",
    "    print(b.classify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluvating classifier\n",
    "To compute the accuracy on our test set, use the accuracy (test_data) method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the show_informative_features method to display a listing of the most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n",
      "         contains(about) = False             neg : pos    =      1.2 : 1.0\n",
      "            contains(am) = False             pos : neg    =      1.2 : 1.0\n",
      "        contains(amzing) = False             neg : pos    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating classifiers with new data\n",
    "use the update(new_Data) method to update classifier with new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data =[\n",
    "    ('she is my best frien','pos'),\n",
    "    (\"i'am happy to have a new friend\", 'pos'),\n",
    "    (\"stay thristy, my friend\", \"pos\"),\n",
    "    (\"Me ain't from arround here\", 'neg')]\n",
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractors\n",
    "by default NaibayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_word_extractor(document):\n",
    "    tokens =document.split()\n",
    "    first_word, last_word =tokens[0], tokens[-1]\n",
    "    feats ={}\n",
    "    feats['first({0})'.format(first_word)]=True\n",
    "    feats['first({0})'.format(last_word)]=False\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =end_word_extractor(\"I love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-79d916395977>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"last(love)\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"first(I)\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert features == {\"last(love)\": False, \"first(I)\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl2 =NaiveBayesClassifier(test, feature_extractor =end_word_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob =TextBlob(\"I'm excited to try my new classifier\", classifier=cl2)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
